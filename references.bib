@inproceedings{Goeau2016,
  title={LifeCLEF bird identification task 2016: The arrival of deep learning},
  author={Go{\"e}au, Herv{\'e} and Glotin, Herv{\'e} and Vellinga, Willem-Pier and Planqu{\'e}, Robert and Joly, Alexis},
  year={2016}
}


@article{Xie2017,
abstract = {Acoustic classification of frogs has received increasing attention for its promising application in ecological studies. Various studies have been proposed for classifying frog species, but most recordings are assumed to have only a single species. In this study, a method to classify multiple frog species in an audio clip is presented. To be specific, continuous frog recordings are first cropped into audio clips (10 seconds). Then, various time-frequency representations are generated for each 10-s recording. Next, instead of using traditional hand-crafted features, various features are extracted using pre-trained networks using three time-frequency representations: Fast-Fourier spectrogram, Constant-Q transform spectrogram, and Gammatone-like spectrogram. Finally, a binary relevance based multi-label classification approach is proposed to classify simultaneously vocalizing frog species with our proposed features. Our proposed method is verified using eight frog species widely distributed in Queensland, Australia. The results show that the proposed features extracted via pre-trained networks can achieve better classification performance when compared to hand-crafted features for classifying multiple simultaneously vocalizing species.},
author = {Xie, Jie and Zeng, Rui and Xu, Changliang and Zhang, Jinglan and Roe, Paul},
doi = {10.1109/eScience.2017.31},
isbn = {9781538626863},
journal = {Proceedings - 13th IEEE International Conference on eScience, eScience 2017},
keywords = {deep learning,frog call classification,multi-label learning,soundscape ecology},
pages = {187--193},
title = {{Multi-label classification of frog species via deep learning}},
year = {2017}
}



@article{Mcloughlin2015,
  title={Robust sound event classification using deep neural networks},
  author={McLoughlin, Ian and Zhang, Haomin and Xie, Zhipeng and Song, Yan and Xiao, Wei},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={23},
  number={3},
  pages={540--552},
  year={2015},
  publisher={IEEE}
}

@article{Mcloughlin2019,
	Author = {Mcloughlin, Michael P and Stewart, Rebecca and McElligott, Alan G},
	Journal = {Journal of the Royal Society Interface},
	Number = {155},
	Pages = {20190225},
	Publisher = {The Royal Society},
	Title = {Automated bioacoustics: methods in ecology and conservation and their potential for animal welfare monitoring},
	Volume = {16},
	Year = {2019}}

@article{Chu2009,
  title={Environmental sound recognition with time--frequency audio features},
  author={Chu, Selina and Narayanan, Shrikanth and Kuo, C-C Jay},
  journal={IEEE Transactions on Audio, Speech, and Language Processing},
  volume={17},
  number={6},
  pages={1142--1158},
  year={2009},
  publisher={IEEE}
}

@article{Foggia2015,
  title={Audio surveillance of roads: A system for detecting anomalous sounds},
  author={Foggia, Pasquale and Petkov, Nicolai and Saggese, Alessia and Strisciuglio, Nicola and Vento, Mario},
  journal={IEEE transactions on intelligent transportation systems},
  volume={17},
  number={1},
  pages={279--288},
  year={2015},
  publisher={IEEE}
}


@article{Wold1996,
  title={Content-based classification, search, and retrieval of audio},
  author={Wold, Erling and Blum, Thom and Keislar, Douglas and Wheaten, James},
  journal={IEEE multimedia},
  volume={3},
  number={3},
  pages={27--36},
  year={1996},
  publisher={IEEE}
}

@article{Ozer2018,
abstract = {Automatic sound recognition (ASR) is a remarkable field of research in recent years. The ability to automatically recognize sound events through computers in a complex audio environment is very useful for machine hearing, acoustic surveillance and multimedia retrieval applications. On the other hand, ASR task become highly difficult as the ambient noise levels increase and many traditional methods show very weak performance under noise. Recent studies has shown that spectrogram image features (SIF) have high performance under noise, while success rates in clean conditions are relatively lower than in the state-of-the-art approaches. In this study, after converting highly overlapped spectrograms into linear quantized images and reducing dimensions by applying various image resizing methods, feature extraction and classification are performed with convolutional neural networks (CNN), which have very high performance in image classification. In the mismatched case, the proposed method achieves a performance improvement of 4.5{\%}, which is equivalent to a relative error reduction of 63.4{\%}, with a classification success of 97.4{\%}, while the multicondition training method achieves an average of 98.63{\%} success rate.},
author = {Ozer, Ilyas and Ozer, Zeynep and Findik, Oguz},
doi = {10.1016/j.neucom.2017.07.021},
file = {:Users/munim/Documents/Mendeley Desktop/Ozer, Ozer, Findik - 2018 - Noise robust sound event classification with convolutional neural network.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Convolutional neural networks,Sound event classification,Spectrogram},
pages = {505--512},
publisher = {Elsevier B.V.},
title = {{Noise robust sound event classification with convolutional neural network}},
url = {https://doi.org/10.1016/j.neucom.2017.07.021},
volume = {272},
year = {2018}
}


@article{Chen2019,
abstract = {Deep learning is currently widely used in a variety of applications, including computer vision and natural language processing. End devices, such as smartphones and Internet-of-Things sensors, are generating data that need to be analyzed in real time using deep learning or used to train deep learning models. However, deep learning inference and training require substantial computation resources to run quickly. Edge computing, where a fine mesh of compute nodes are placed close to end devices, is a viable way to meet the high computation and low-latency requirements of deep learning on edge devices and also provides additional benefits in terms of privacy, bandwidth efficiency, and scalability. This paper aims to provide a comprehensive review of the current state of the art at the intersection of deep learning and edge computing. Specifically, it will provide an overview of applications where deep learning is used at the network edge, discuss various approaches for quickly executing deep learning inference across a combination of end devices, edge servers, and the cloud, and describe the methods for training deep learning models across multiple edge devices. It will also discuss open challenges in terms of systems performance, network technologies and management, benchmarks, and privacy. The reader will take away the following concepts from this paper: understanding scenarios where deep learning at the network edge can be useful, understanding common techniques for speeding up deep learning inference and performing distributed training on edge devices, and understanding recent trends and opportunities.},
author = {Chen, Jiasi and Ran, Xukan and Computer, Islvrc and Competition, Vision},
doi = {10.1109/JPROC.2019.2921977},
file = {:Users/munim/Documents/Mendeley Desktop/Chen et al. - 2019 - Deep Learning With Edge Computing A Review.pdf:pdf},
issn = {15582256},
journal = {Proceedings of the IEEE},
keywords = {Artificial intelligence,edge computing,machine learning,mobile computing,neural networks.},
number = {8},
title = {{Deep Learning With Edge Computing: A Review}},
volume = {107},
year = {2019}
}



@inproceedings{Kahl2019,
abstract = {The BirdCLEF challenge-as part of the 2019 LifeCLEF Lab [7]-offers a large-scale proving ground for system-oriented evaluation of bird species identification based on audio recordings. The challenge uses data collected through Xeno-canto, the worldwide community of bird sound recordists. This ensures that BirdCLEF is close to the conditions of real-world application, in particular with regard to the number of species in the training set (659). In 2019, the challenge was focused on the difficult task of recognizing all birds vocalizing in omni-directional soundscape recordings. Therefore, the dataset of the previous year was extended with more than 350 hours of manually annotated soundscapes that were recorded using 30 field recorders in Ithaca (NY, USA). This paper describes the methodology of the conducted evaluation as well as the synthesis of the main results and lessons learned.},
author = {Kahl, Stefan and St{\"{o}}ter, Fabian Robert and Go{\"{e}}au, Herv{\'{e}} and Glotin, Herv{\'{e}} and Planqu{\'{e}}, Robert and Vellinga, Willem Pier and Joly, Alexis},
booktitle = {CEUR Workshop Proceedings},
file = {:home/munim/Documents/Mendeley Desktop/Kahl et al. - 2019 - Overview of BIRDCLEF 2019 Large-scale bird recognition in soundscapes.pdf:pdf},
issn = {16130073},
mendeley-groups = {Bird ID},
title = {{Overview of BIRDCLEF 2019: Large-scale bird recognition in soundscapes}},
volume = {2380},
year = {2019}
}



@article{Ruff2019,
abstract = {Passive acoustic monitoring is an emerging approach to wildlife monitoring that leverages recent improvements in automated recording units and other technologies. A central challenge of this approach is the task of locating and identifying target species vocalizations in large volumes of audio data. To address this issue, we developed an efficient data processing pipeline using a deep convolutional neural network (CNN) to automate the detection of owl vocalizations in spectrograms generated from unprocessed field recordings. While the project was initially focused on spotted and barred owls, we also trained the network to recognize northern saw-whet owl, great horned owl, northern pygmy-owl, and western screech-owl. Although classification performance varies across species, initial results are promising. Recall, or the proportion of calls in the dataset that are detected and correctly identified, ranged from 63.1{\%} for barred owl to 91.5{\%} for spotted owl based on raw network output. Precision, the rate of true positives among apparent detections, ranged from 0.4{\%} for spotted owl to 77.1{\%} for northern saw-whet owl based on raw output. In limited tests, the CNN performed as well as or better than human technicians at detecting owl calls. Our model output is suitable for developing species encounter histories for occupancy models and other analyses. We believe our approach is sufficiently general to support long-term, large-scale monitoring of a broad range of species beyond our target species list, including birds, mammals, and others.},
author = {Ruff, Zachary J. and Lesmeister, Damon B. and Duchac, Leila S. and Padmaraju, Bharath K. and Sullivan, Christopher M.},
doi = {10.1002/rse2.125},
editor = {Pettorelli, Nathalie and Lecours, Vincent},
file = {:home/munim/Documents/Mendeley Desktop/rse2.125.pdf:pdf},
issn = {2056-3485},
journal = {Remote Sensing in Ecology and Conservation},
mendeley-groups = {Bird Detect},
month = {9},
pages = {rse2.125},
title = {{Automated identification of avian vocalizations with deep convolutional neural networks}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rse2.125},
year = {2019}
}


@article{Garcia2019,
abstract = {Energy consumption has been widely studied in the computer architecture field for decades. While the adoption of energy as a metric in machine learning is emerging, the majority of research is still primarily focused on obtaining high levels of accuracy without any computational constraint. We believe that one of the reasons for this lack of interest is due to their lack of familiarity with approaches to evaluate energy consumption. To address this challenge, we present a review of the different approaches to estimate energy consumption in general and machine learning applications in particular. Our goal is to provide useful guidelines to the machine learning community giving them the fundamental knowledge to use and build specific energy estimation methods for machine learning algorithms. We also present the latest software tools that give energy estimation values, together with two use cases that enhance the study of energy consumption in machine learning.},
author = {Garc{\'{i}}a-Mart{\'{i}}n, Eva and Rodrigues, Crefeda Faviola and Riley, Graham and Grahn, H{\aa}kan},
doi = {10.1016/j.jpdc.2019.07.007},
file = {:home/munim/Documents/Mendeley Desktop/1-s2.0-S0743731518308773-main.pdf:pdf},
issn = {07437315},
journal = {Journal of Parallel and Distributed Computing},
keywords = {,Deep learning,Energy consumption,GreenAI,High performance computing,Machine learning},
pages = {75--88},
publisher = {Elsevier},
title = {{Estimation of energy consumption in machine learning}},
url = {https://doi.org/10.1016/j.jpdc.2019.07.007},
volume = {134},
year = {2019}
}


@article{Kuaga2019,
author = {Ku{\l}aga, Kinga and Budka, Micha{\l}},
doi = {10.1371/journal.pone.0211970},
editor = {P{\'{e}}rez-Garc{\'{i}}a, Juan Manuel},
issn = {1932-6203},
journal = {PLOS ONE},
mendeley-groups = {Bird IoT},
number = {2},
pages = {e0211970},
title = {{Bird species detection by an observer and an autonomous sound recorder in two different environments: Forest and farmland}},
url = {http://dx.plos.org/10.1371/journal.pone.0211970},
volume = {14},
year = {2019}
}


@article{Xie2018b,
	Author = {Xie, Jie and Towsey, Michael and Zhang, Jinglan and Roe, Paul},
	Date = {2018},
	Doi = {10.1007/s10462-016-9529-z},
	Isbn = {0449002446},
	Journaltitle = {Artificial Intelligence Review},
	Number = {3},
	Pages = {375--391},
	Title = {Frog call classification: a survey},
	Volume = {49},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10462-016-9529-z}}
	
@article{Xie2018,
author = {Xie, Jiang-jian and Ding, Chang-qing and Li, Wen-bin and Cai, Cheng-hao and Jiang-jian, Xie and Chang-qing, Ding and Wen-bin, Li and Cheng-hao, Cai},
eprint = {1803.01107},
file = {:home/munim/Documents/Mendeley Desktop/Xie et al. - 2018 - Audio-only Bird Species Automated Identification Method with Limited Training Data Based on Multi-Channel Deep Convo.pdf:pdf},
mendeley-groups = {Bird ID},
month = {3},
title = {{Audio-only Bird Species Automated Identification Method with Limited Training Data Based on Multi-Channel Deep Convolutional Neural Networks}},
url = {https://arxiv.org/pdf/1803.01107.pdf http://arxiv.org/abs/1803.01107},
year = {2018}
}


@article{Sugai2019,
author = {Sugai, Larissa Sayuri Moreira and Silva, Thiago Sanna Freire and Ribeiro, Jos{\'{e}} Wagner and Llusia, Diego},
doi = {10.1093/biosci/biy147},
file = {:Users/munim/Documents/Mendeley Desktop/Sugai et al. - 2019 - Terrestrial Passive Acoustic Monitoring Review and Perspectives.pdf:pdf},
issn = {15253244},
journal = {BioScience},
keywords = {Audio recorders,auditory monitoring,automated data collection,bioacoustics,ecoacoustics,faunal survey,soundscapes},
number = {1},
pages = {5--11},
title = {{Terrestrial Passive Acoustic Monitoring: Review and Perspectives}},
volume = {69},
year = {2019}
}



@article{Vestias2019,
author = {Mário P. Véstias},
doi = {10.3390/a12080154},
file = {:Users/munim/Documents/Mendeley Desktop/V{\'{e}}stias - 2019 - A Survey of Convolutional Neural Networks on Edge with Reconfigurable Computing.pdf:pdf},
journal = {Algorithms},
keywords = {convolutional neural network,deep learning,edge inference,field-programmable,gate array,reconfigurable computing},
number = {8},
pages = {154},
title = {{A Survey of Convolutional Neural Networks on Edge with Reconfigurable Computing}},
volume = {12},
year = {2019}
}


@article{Vestias2018,
author = {Vestias, Mario and {Policarpo Duarte}, Rui and {De Sousa}, Jose T. and Neto, Horacio C.},
doi = {10.1109/FPL.2018.00075},
file = {:Users/munim/Documents/Mendeley Desktop/Vestias et al. - 2018 - Lite-CNN A high-performance architecture to execute CNNs in low density FPGAs(2).pdf:pdf},
isbn = {9781538685174},
journal = {Proceedings - 2018 International Conference on Field-Programmable Logic and Applications, FPL 2018},
keywords = {Convolutional Neural Network,Deep learning,Embedded computing,Field-Programmable Gate Array},
pages = {399--402},
title = {{Lite-CNN: A high-performance architecture to execute CNNs in low density FPGAs}},
year = {2018}
}


@inproceedings{Vanhoucke2011,
title	= {Improving the speed of neural networks on {CPUs}},
author	= {Vincent Vanhoucke and Andrew Senior and Mark Z. Mao},
year	= {2011},
booktitle	= {Deep Learning and Unsupervised Feature Learning Workshop, NIPS 2011}
}




@article {Sahidullah2012,
  title = {Comparison of speech activity detection techniques for speaker recognition},
  author = {Sahidullah, Md and Saha, Goutam},
  journal = {arXiv preprint arXiv: 1210.0297},
  year = {2012}
}
@inproceedings{Salamon2014,
  title={A dataset and taxonomy for urban sound research},
  author={Salamon, Justin and Jacoby, Christopher and Bello, Juan Pablo},
  booktitle={Proceedings of the 22nd ACM international conference on Multimedia},
  pages={1041--1044},
  year={2014},
  organization={ACM}
}

@book{Evans2002,
	Author = {Evans, William R and O'Brien, Michael},
	Publisher = {Old Bird Incorporated},
	Title = {Flight calls of migratory birds: Eastern North American landbirds},
	Year = {2002}}

@article{Sigtia2016,
	Author = {Sigtia, Siddharth and Stark, Adam M. and Krstulović, Sacha and Plumbley, Mark D. and Krstulovic, Sacha and Plumbley, Mark D.},
	Doi = {10.1109/TASLP.2016.2592698},
	Eprint = {arXiv:1607.04589v1},
	Journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
	Month = {7},
	Number = {11},
	Pages = {2096--2107},
	Publisher = {IEEE},
	Title = {{Automatic Environmental Sound Recognition: Performance Versus Computational Cost}},
	Url = {http://arxiv.org/abs/1607.04589 http://dx.doi.org/10.1109/TASLP.2016.2592698},
	Volume = {24},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1607.04589%20http://dx.doi.org/10.1109/TASLP.2016.2592698},
	Bdsk-Url-2 = {https://doi.org/10.1109/TASLP.2016.2592698}}

@inproceedings{Ebbers2018,
	Author = {Ebbers, Janek and Heitkaemper, Jens and Schmalenstroeer, Joerg and Haeb-Umbach, Reinhold},
	Booktitle = {Proc. of ITG Fachtagung Sprachkommunikation (Speech Communications)},
	Isbn = {9783800747672},
	Number = {October},
	Pages = {171--175},
	Title = {{Benchmarking neural network architectures for acoustic sensor networks}},
	Year = {2018}}

@inproceedings{Takahashi2016,
	Archiveprefix = {arXiv},
	Arxivid = {1604.07160},
	Author = {Takahashi, Naoya and Gygli, Michael and Pfister, Beat and {Van Gool}, Luc},
	Booktitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	Doi = {10.21437/Interspeech.2016-805},
	Eprint = {1604.07160},
	File = {:home/munim/Documents/Mendeley Desktop/Takahashi et al. - 2016 - Deep Convolutional Neural Networks and Data Augmentation for Acoustic Event Detection.pdf:pdf},
	Issn = {19909772},
	Keywords = {Acoustic event recognition,Convolutional neural networks,Data augmentation,Large input field},
	Mendeley-Groups = {Bird Detect,Bird ID},
	Month = {4},
	Pages = {2982--2986},
	Title = {{Deep convolutional neural networks and data augmentation for acoustic event recognition}},
	Url = {http://arxiv.org/abs/1604.07160},
	Volume = {08-12-Sept},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1604.07160},
	Bdsk-Url-2 = {https://doi.org/10.21437/Interspeech.2016-805}}

@article{Abdoli2019,
	Author = {Abdoli, Sajjad and Cardinal, Patrick and Koerich, Alessandro Lameiras},
	Date = {2019},
	Journaltitle = {Expert Systems with Applications},
	Publisher = {Elsevier},
	Title = {End-to-End Environmental Sound Classification using a 1D Convolutional Neural Network}}

@article{Meyer2017,
	Archiveprefix = {arXiv},
	Arxivid = {1709.09888},
	Author = {Meyer, Matthias and Cavigelli, Lukas and Thiele, Lothar},
	Eprint = {1709.09888},
	Month = {9},
	Title = {{Efficient convolutional neural network for audio event detection}},
	Url = {http://arxiv.org/abs/1709.09888},
	Year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1709.09888}}

@inproceedings{Horowitz2014,
	Author = {Horowitz, Mark},
	Booktitle = {2014 IEEE International Solid-State Circuits Conference Digest of Technical Papers (ISSCC)},
	Doi = {10.1109/ISSCC.2014.6757323},
	Mendeley-Groups = {BNN},
	Month = {2},
	Organization = {IEEE},
	Pages = {10--14},
	Publisher = {IEEE},
	Title = {{Computing's energy problem (and what we can do about it)}},
	Url = {http://ieeexplore.ieee.org/document/6757323/},
	Volume = {57},
	Year = {2014},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/document/6757323/},
	Bdsk-Url-2 = {https://doi.org/10.1109/ISSCC.2014.6757323}}

@article{Kim2016a,
	Archiveprefix = {arXiv},
	Arxivid = {1601.06071},
	Author = {Kim, Minje and Smaragdis, Paris},
	Eprint = {1601.06071},
	Title = {{Bitwise neural networks}},
	Url = {http://arxiv.org/abs/1601.06071},
	Volume = {37},
	Year = {2016},
	Bdsk-Url-1 = {http://arxiv.org/abs/1601.06071}}

@article{Babaee2017,
	Author = {Babaee, Elham and Anuar, Nor Badrul and {Abdul Wahab}, Ainuddin Wahid and Shamshirband, Shahaboddin and Chronopoulos, Anthony T.},
	Doi = {10.1080/08839514.2018.1430469},
	Issn = {10876545},
	Journal = {Applied Artificial Intelligence},
	Number = {9-10},
	Pages = {661--714},
	Publisher = {Taylor {\&} Francis},
	Title = {{An overview of audio event detection methods from feature extraction to classification}},
	Url = {https://doi.org/10.1080/08839514.2018.1430469},
	Volume = {31},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1080/08839514.2018.1430469}}



@article{Priyadarshani2018,
	Author = {Priyadarshani, Nirosha and Castro, Isabel and Marsland, Stephen},
	Doi = {10.1002/ece3.3889},
	Issn = {20457758},
	Journal = {Ecology and Evolution},
	Keywords = {automatic acoustic recorders,birdsong attenuation,ecoacoustics,frequency,transmission height,wind},
	Mendeley-Groups = {Bird ID},
	Month = {6},
	Number = {10},
	Pages = {5016--5033},
	Title = {{The impact of environmental factors in birdsong acquisition using automated recorders}},
	Url = {http://doi.wiley.com/10.1002/ece3.3889},
	Volume = {8},
	Year = {2018},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1002/ece3.3889},
	Bdsk-Url-2 = {https://doi.org/10.1002/ece3.3889}}

@article{Priyadarshani2018a,
	Author = {Priyadarshani, Nirosha and Marsland, Stephen and Castro, Isabel},
	Date = {2018},
	Journaltitle = {Journal of Avian Biology},
	Number = {5},
	Publisher = {Wiley Online Library},
	Title = {Automated birdsong recognition in complex acoustic environments: a review},
	Volume = {49}}

@inproceedings{Grill2017,
	Author = {Grill, Thomas and Schluter, Jan},
	Booktitle = {25th European Signal Processing Conference, EUSIPCO 2017},
	Doi = {10.23919/EUSIPCO.2017.8081512},
	Isbn = {9780992862671},
	Month = {8},
	Pages = {1764--1768},
	Publisher = {IEEE},
	Title = {{Two convolutional neural networks for bird detection in audio signals}},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.23919/EUSIPCO.2017.8081512}}

@inproceedings{Rastegari2016,
	Author = {Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
	Booktitle = {European Conference on Computer Vision},
	Organization = {Springer},
	Pages = {525--542},
	Title = {{XNOR-Net}: Imagenet classification using binary convolutional neural networks},
	Year = {2016}}

@article{Courbariaux2016,
	Archiveprefix = {arXiv},
	Author = {Courbariaux, Matthieu and Hubara, Itay and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
	Eprint = {1602.02830},
	Title = {Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1},
	Year = {2016}}

@article{Fagerlund2003,
	Author = {Fagerlund, Seppo},
	Journal = {Laboratory of Acoustics and Signal Processing, HUT, {\ldots}},
	Number = {Brackenbury 1989},
	Pages = {1--13},
	Title = {{Acoustics and physical models of bird sounds}},
	Url = {https://www.acoustics.hut.fi/research/avesound/pubs/akusem04.pdf},
	Year = {2003},
	Bdsk-Url-1 = {https://www.acoustics.hut.fi/research/avesound/pubs/akusem04.pdf}}

@inproceedings{Yin2018,
	Author = {Yin, Shouyi and Ouyang, Peng and Zheng, Shixuan and Song, Dandan and Li, Xiudong and Liu, Leibo and Wei, Shaojun},
	Booktitle = {2018 IEEE Symposium on VLSI Circuits},
	Doi = {10.1109/VLSIC.2018.8502309},
	Month = {6},
	Pages = {139--140},
	Publisher = {IEEE},
	Title = {{A 141 uW, 2.46 pJ/neuron binarized convolutional neural network based self-learning speech recognition processor in 28nm CMOS}},
	Url = {https://ieeexplore.ieee.org/document/8502309/},
	Year = {2018},
	Bdsk-Url-1 = {https://ieeexplore.ieee.org/document/8502309/},
	Bdsk-Url-2 = {https://doi.org/10.1109/VLSIC.2018.8502309}}

@article{Liu2019,
	Author = {Liu, Bo and Wang, Zhen and Fan, Hu and Yang, Jing and Zhu, Wentao and Huang, Lepeng and Gong, Yu and Ge, Wei and Shi, Longxing},
	Doi = {10.1109/ACCESS.2019.2924340},
	Isbn = {0103110100},
	Issn = {21693536},
	Journal = {IEEE Access},
	Keywords = {approximate computing,binary weight network,spotting},
	Mendeley-Groups = {Liteweight KWS},
	Pages = {82453--82465},
	Publisher = {IEEE},
	Title = {{EERA-KWS: A 163 TOPS/W always-on keyword spotting accelerator in 28nm CMOS using binary weight network and precision self-adaptive approximate computing}},
	Volume = {7},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1109/ACCESS.2019.2924340}}

@article{Stowell2015,
	Author = {Stowell, Dan and Giannoulis, Dimitrios and Benetos, Emmanouil and Lagrange, Mathieu and Plumbley, Mark D.},
	Doi = {10.1109/TMM.2015.2428998},
	Eprint = {arXiv:1708.03211v2},
	Isbn = {9781479909728},
	Issn = {15209210},
	Journal = {IEEE Transactions on Multimedia},
	Number = {10},
	Pages = {1733--1746},
	Title = {{Detection and classification of acoustic scenes and events}},
	Volume = {17},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1109/TMM.2015.2428998}}

@thesis{Camargo2019,
	Author = {de Camargo, Ulissen Moliterno},
	Date = {2019},
	Institution = {University of Helsinki},
	Title = {Large-scale automated acoustic monitoring of birds and the challenges of field data}}

@article{Crocco2016,
	Author = {Crocco, Marco and Cristani, Marco and Trucco, Andrea and Murino, Vittorio},
	Date = {2016},
	Journaltitle = {ACM Computing Surveys (CSUR)},
	Number = {4},
	Pages = {52},
	Publisher = {ACM},
	Title = {Audio surveillance: A systematic review},
	Volume = {48}}

@inproceedings{Kumar2016,
	Author = {Kumar, Anurag and Raj, Bhiksha},
	Booktitle = {Proceedings of the 24\textsuperscript{th} ACM international conference on Multimedia},
	Date = {2016},
	Organization = {ACM},
	Pages = {1038--1047},
	Title = {Audio event detection using weakly labeled data}}

@article{Sharma2015,
	Arxivid = {arXiv:1908.11219v2},
	Author = {Sharma, Jivitesh and Granmo, Ole-christoffer and Goodwin, Morten},
	Date = {2015},
	Eprint = {arXiv:1908.11219v2},
	Eprinttype = {arXiv},
	Mendeley-Groups = {PD},
	Number = {8},
	Pages = {1--11},
	Title = {Environment Sound Classification using Multiple Feature Channels and Deep Convolutional Neural Networks},
	Volume = {14}}

@article{Bardeli2010,
	Author = {Bardeli, R. and Wolff, D. and Kurth, F. and Koch, M. and Tauchert, K. H. and Frommolt, K. H.},
	Date = {2010},
	Doi = {10.1016/j.patrec.2009.09.014},
	Journaltitle = {Pattern Recognition Letters},
	Keywords = {Algorithmic bioacoustics,Animal sounds,Bioacoustic monitoring},
	Number = {12},
	Pages = {1524--1534},
	Publisher = {Elsevier B.V.},
	Title = {Detecting bird sounds in a complex acoustic environment and application to bioacoustic monitoring},
	Volume = {31},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.patrec.2009.09.014}}

@article{Kucuktopcu2019,
	Author = {Kucuktopcu, Okan and Masazade, Engin and Unsalan, Cem and Varshney, Pramod Kumar},
	Date = {2019},
	Journaltitle = {Applied Acoustics},
	Pages = {194--201},
	Publisher = {Elsevier Limited},
	Title = {A real-time bird sound recognition system using a low-cost microcontroller},
	Volume = {148}}

@inproceedings{Salamon2017a,
	Author = {Salamon, Justin and MacConnell, Duncan and Cartwright, Mark and Li, Peter and Bello, Juan Pablo},
	Booktitle = {2017 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)},
	Date = {2017},
	Organization = {IEEE},
	Pages = {344--348},
	Title = {Scaper: A library for soundscape synthesis and augmentation}}

@inproceedings{Salekin2019,
	Author = {Salekin, Asif and Ghaffarzadegan, Shabnam and Feng, Zhe and Stankovic, John},
	Booktitle = {2019 15\textsuperscript{th} International Conference on Distributed Computing in Sensor Systems (DCOSS)},
	Date = {2019},
	Organization = {IEEE},
	Pages = {98--105},
	Title = {A Real-Time Audio Monitoring Framework with Limited Data for Constrained Devices}}

@article{Cardoso2011,
	Author = {Cardoso, Gon{\c c}alo C and Atwell, Jonathan W},
	Date = {2011},
	Journaltitle = {Animal Behaviour},
	Number = {4},
	Pages = {831--836},
	Publisher = {Elsevier},
	Title = {On the relation between loudness and the increased song frequency of urban birds},
	Volume = {82}}

@article{Zhang2015,
	Author = {Zhang, Xiaoxia and Li, Ying},
	Date = {2015},
	Journaltitle = {Neurocomputing},
	Pages = {108--116},
	Publisher = {Elsevier},
	Title = {Adaptive energy detection for bird sound detection in complex environments},
	Volume = {155}}

@article{Ntalampiras2018,
	Author = {Ntalampiras, Stavros},
	Date = {2018},
	Journaltitle = {Ecological informatics},
	Pages = {76--81},
	Publisher = {Elsevier},
	Title = {Bird species identification via transfer learning from music genres},
	Volume = {44}}

@inproceedings{Sevilla2017,
	Author = {Sevilla, Antoine and Glotin, Herv{\'e}},
	Booktitle = {CLEF (Working Notes)},
	Date = {2017},
	Title = {Audio bird classification with Inception-v4 extended with time and time-frequency attention mechanisms}}

@article{Fazekas2018,
	Arxivid = {1811.04448},
	Author = {Fazekas, Botond and Schindler, Alexander and Lidy, Thomas and Rauber, Andreas},
	Date = {2018-11},
	Eprint = {1811.04448},
	Eprinttype = {arXiv},
	Mendeley-Groups = {Bird ID},
	Title = {A multi-modal deep neural network approach to bird-song identification},
	Url = {http://arxiv.org/abs/1811.04448},
	Bdsk-Url-1 = {http://arxiv.org/abs/1811.04448}}

@article{Kahl2017,
	Author = {Kahl, Stefan and Wilhelm-Stein, Thomas and Hussein, Hussein and Klinck, Holger and Kowerko, Danny and Ritter, Marc and Eibl, Maximilian},
	Date = {2017},
	Journaltitle = {CEUR Workshop Proceedings},
	Keywords = {Audio features,Bioacoustics,Bird sound identification,BirdCLEF 2017,Convolutional neural networks,Large-scale classification},
	Mendeley-Groups = {Bird ID},
	Title = {Large-scale bird sound classification using convolutional neural networks},
	Volume = {1866}}

@inproceedings{Fritzler2017,
	Author = {Fritzler, Andreas and Koitka, Sven and Friedrich, Christoph M},
	Booktitle = {CLEF (Working Notes)},
	Date = {2017},
	Title = {Recognizing bird species in audio files using transfer learning.}}

@article{Albornoz2017,
	Author = {Albornoz, Enrique M. and Vignolo, Leandro D. and Sarquis, Juan A. and Leon, Evelina},
	Date = {2017-03},
	Journaltitle = {Ecological Informatics},
	Keywords = {Bird sound classification,Computational bioacoustics,Furnariidae,Machine learning,Speech-related features},
	Pages = {39--49},
	Publisher = {Elsevier},
	Title = {Automatic classification of Furnariidae species from the Paranaense Littoral region using speech-related features and machine learning},
	Url = {https://www.sciencedirect.com/science/article/pii/S1574954117300286?via{\%}3Dihub},
	Volume = {38}}

@article{Sprengel2016,
	Author = {Sprengel, Elias and Jaggi, Martin and Kilcher, Yannic and Hofmann, Thomas},
	Date = {2016},
	Journaltitle = {CEUR Workshop Proceedings},
	Keywords = {Acoustic classification,Audio Processing,Bird Identification,Bird Species Recognition,Convolution Neural Net-work,Convolution Neural Network,Data Augmentation,Deep Learning},
	Mendeley-Groups = {Bird ID},
	Pages = {547--559},
	Title = {Audio based bird species identification using deep learning techniques},
	Url = {http://www.ethz.ch},
	Volume = {1609},
	Bdsk-Url-1 = {http://www.ethz.ch}}

@inproceedings{Zottesso2016,
	Author = {Rafael H. D. Zottesso and Matsushita, Gustavo H. G. and Lucio, Diego Rafael and Costa, Yandre M. G.},
	Booktitle = {2016 35\textsuperscript{th} International Conference of the Chilean Computer Science Society (SCCC)},
	Date = {2016-10},
	Doi = {10.1109/SCCC.2016.7836062},
	Isbn = {978-1-5090-3339-3},
	Mendeley-Groups = {Bird ID},
	Pages = {1--11},
	Publisher = {IEEE},
	Title = {Automatic segmentation of audio signal in bird species identification},
	Url = {http://ieeexplore.ieee.org/document/7836062/},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/document/7836062/},
	Bdsk-Url-2 = {https://doi.org/10.1109/SCCC.2016.7836062}}

@inproceedings{Chou2007,
	Author = {Chou, Chih-Hsun and Lee, Chang-Hsing and Ni, Hui-Wen},
	Booktitle = {Second International Conference on Innovative Computing, Informatio and Control (ICICIC 2007)},
	Date = {2007-09},
	Doi = {10.1109/ICICIC.2007.199},
	Isbn = {0-7695-2882-1},
	Mendeley-Groups = {Bird ID},
	Pages = {143--143},
	Publisher = {IEEE},
	Title = {Bird species recognition by comparing the HMMs of the syllables},
	Url = {http://ieeexplore.ieee.org/document/4427788/},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/document/4427788/},
	Bdsk-Url-2 = {https://doi.org/10.1109/ICICIC.2007.199}}

@inproceedings{Lucio2015,
	Author = {Lucio, Diego Rafael and Maldonado, Yandre and da Costa, Gomes},
	Booktitle = {2015 Latin American Computing Conference (CLEI)},
	Date = {2015-10},
	Doi = {10.1109/CLEI.2015.7359990},
	Isbn = {978-1-4673-9143-6},
	Mendeley-Groups = {Bird ID},
	Pages = {1--11},
	Publisher = {IEEE},
	Title = {Bird species classification using spectrograms},
	Url = {http://ieeexplore.ieee.org/document/7359990/},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/document/7359990/},
	Bdsk-Url-2 = {https://doi.org/10.1109/CLEI.2015.7359990}}

@inproceedings{Marini2015,
	Author = {Marini, A. and Turatti, A. J. and Britto, A. S. and Koerich, A. L.},
	Booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	Date = {2015},
	Doi = {10.1109/ICASSP.2015.7178383},
	Isbn = {9781467369978},
	Keywords = {MFCC,SIFT,combination of classifiers,fine-grained classification,fusion of information},
	Pages = {2309--2313},
	Publisher = {IEEE},
	Title = {Visual and acoustic identification of bird species},
	Volume = {2015-Augus},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICASSP.2015.7178383}}

@inproceedings{Lopes2011,
	Author = {M. T. Lopes and C. N. Silla Junior and A. L. Koerich and C. A. A. Kaestner},
	Booktitle = {2011 IEEE International Conference on Systems, Man, and Cybernetics},
	Date = {2011-10},
	Doi = {10.1109/ICSMC.2011.6083794},
	Pages = {965--970},
	Title = {Feature set comparison for automatic bird species identification},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICSMC.2011.6083794}}

@inproceedings{Cai2007,
	Author = {J. Cai and D. Ee and B. Pham and P. Roe and J. Zhang},
	Booktitle = {2007 3\textsuperscript{rd} International Conference on Intelligent Sensors, Sensor Networks and Information},
	Date = {2007-12},
	Doi = {10.1109/ISSNIP.2007.4496859},
	Pages = {293--298},
	Title = {Sensor network for the monitoring of ecosystem: Bird species recognition},
	Bdsk-Url-1 = {https://doi.org/10.1109/ISSNIP.2007.4496859}}

@article{Kogan1998,
	Author = {Kogan, Joseph A and Margoliash, Daniel},
	Date = {1998},
	Journaltitle = {The Journal of the Acoustical Society of America},
	Number = {4},
	Pages = {2185--2196},
	Publisher = {ASA},
	Title = {Automated recognition of bird song elements from continuous recordings using dynamic time warping and hidden Markov models: A comparative study},
	Volume = {103}}

@article{SouzaFilho2014,
	Author = {Souza Filho, Nilson Evil{\'a}sio and Oliveira, Beatriz Cerimeli and da Silva, Maria Luisa and Vielliard, Jacques},
	Date = {2014},
	Doi = {10.5902/2179460x11303},
	Journaltitle = {Ci{\^e}ncia e Natura},
	Keywords = {biacoustic,classification,rufous-bellied thrush,spectrogram,template-matching},
	Number = {2},
	Pages = {646--654},
	Title = {Automatic Classification of Turdus Rufiventris Song Notes By Spectrographic Image Template Matching},
	Volume = {36},
	Bdsk-Url-1 = {https://doi.org/10.5902/2179460x11303}}

@mastersthesis{Nordby2019,
	Author = {Nordby, Jon Opedal},
	Date = {2019},
	Institution = {Norwegian University of Life Sciences, {\AA}s},
	Title = {Environmental sound classification on microcontrollers using Convolutional Neural Networks}}

@inproceedings{Zhang2018b,
	Author = {Zhang, Xiaohu and Zou, Yuexian and Wang, Wenwu},
	Booktitle = {2018 24\textsuperscript{th} International Conference on Pattern Recognition (ICPR)},
	Date = {2018},
	Organization = {IEEE},
	Pages = {373--378},
	Title = {LD-CNN: A Lightweight Dilated Convolutional Neural Network for Environmental Sound Classification}}

@article{Salamon2017,
	Author = {Salamon, Justin and Bello, Juan Pablo},
	Date = {2017},
	Journaltitle = {IEEE Signal Processing Letters},
	Number = {3},
	Pages = {279--283},
	Publisher = {IEEE},
	Title = {Deep convolutional neural networks and data augmentation for environmental sound classification},
	Volume = {24}}

@inproceedings{Piczak2015,
	Author = {Piczak, Karol J},
	Booktitle = {2015 IEEE 25\textsuperscript{th} International Workshop on Machine Learning for Signal Processing (MLSP)},
	Date = {2015},
	Organization = {IEEE},
	Pages = {1--6},
	Title = {Environmental sound classification with convolutional neural networks}}

@article{Huzaifah2017,
	Author = {Huzaifah, Muhammad},
	Date = {2017},
	Journaltitle = {arXiv preprint arXiv:1706.07156},
	Title = {Comparison of time-frequency representations for environmental sound classification using convolutional neural networks}}

@inproceedings{Fonseca2017,
	Author = {Fonseca, Eduardo and Pons Puig, Jordi and Favory, Xavier and Font Corbera, Frederic and Bogdanov, Dmitry and Ferraro, Andres and Oramas, Sergio and Porter, Alastair and Serra, Xavier},
	Booktitle = {Hu X, Cunningham SJ, Turnbull D, Duan Z, editors. Proceedings of the 18\textsuperscript{th} ISMIR Conference; 2017 oct 23-27; Suzhou, China.[Canada]: International Society for Music Information Retrieval; 2017. p. 486-93.},
	Date = {2017},
	Organization = {International Society for Music Information Retrieval (ISMIR)},
	Title = {Freesound datasets: a platform for the creation of open audio datasets}}

@inproceedings{Piczak2015a,
	Author = {Piczak, Karol J},
	Booktitle = {Proceedings of the 23\textsuperscript{rd} ACM international conference on Multimedia},
	Date = {2015},
	Organization = {ACM},
	Pages = {1015--1018},
	Title = {ESC: Dataset for environmental sound classification}}

@article{Oreilly2017,
	Author = {O'Reilly, Colm and Harte, Naomi},
	Date = {2017-04},
	Doi = {10.1080/23312025.2017.1322025},
	Editor = {Burda, Hynek},
	Journaltitle = {Cogent Biology},
	Keywords = {bird song,bird vocalizations,pitch tracking},
	Mendeley-Groups = {Bird ID},
	Number = {1},
	Pages = {1--27},
	Publisher = {Cogent},
	Title = {Pitch tracking of bird vocalizations and an automated process using YIN-bird},
	Url = {https://doi.org/10.1080/23312025.2017.1322025 https://www.cogentoa.com/article/10.1080/23312025.2017.1322025},
	Volume = {3},
	Bdsk-Url-1 = {https://doi.org/10.1080/23312025.2017.1322025%20https://www.cogentoa.com/article/10.1080/23312025.2017.1322025},
	Bdsk-Url-2 = {https://doi.org/10.1080/23312025.2017.1322025}}

@article{Potamitis2015,
	Abstract = {A broad range of organisations and individuals are collecting wildlife audio recordings. Huge amounts of audio data have been gathered in the past and since the popularisation of automatic recording units the data are piling up exponentially. The point in gathering them is to analyse them, evaluate insights and hypotheses, identify patterns of activity that are otherwise not apparent and finally design policies on biodiversity issues. For massive volumes of data even visual inspection of spectrograms is unfeasible and interesting cases that could provide valuable insight for concrete hypotheses on the biodiversity status can slip into bliss. In this paper we research a range of techniques that work with minor human supervision. These techniques will construct a dictionary of templates extracted in an unsupervised way from reference recordings and then crawl over a large number of recordings to examine the underlying bioacoustic activity. This work is general and we have applied it to many datasets of animal's vocalisations (e.g. cetaceans, mice, birds). To test our tools objectively and for the sake of reproducibility in this work we report on the MLSP 2013 bird dataset that recently has been publicly released along with all its annotations. We are not interested as to which is the best scoring approach for this dataset. Our aim is to describe novel machine learning tools that try to refine our understanding of biodiversity by answering questions such as: Is the recording under examination void of bird vocalisations or not? If there is bird activity, how many different species are in the recording? What are the most important characteristic spectral segments for recognizing a specific species? The database however is valuable to us to quantify our findings.},
	Author = {Potamitis, Ilyas},
	Date = {2015},
	Doi = {10.1016/j.ecoinf.2015.01.002},
	Journaltitle = {Ecological Informatics},
	Keywords = {Automatic recognition of species,Computational ecology,Ecological informatics,Large-taxa audio classification},
	Title = {Unsupervised dictionary extraction of bird vocalisations and new tools on assessing and visualising bird activity},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.ecoinf.2015.01.002}}

@inproceedings{Lasseck2015,
	Author = {Lasseck, Mario},
	Booktitle = {Experimental IR Meets Multilinguality, Multimodality, and Interaction},
	Date = {2015},
	Editor = {Mothe, Josanne and Savoy, Jacques and Kamps, Jaap and Pinel-Sauvagnat, Karen and Jones, Gareth and San Juan, Eric and Capellato, Linda and Ferro, Nicola},
	Isbn = {978-3-319-24027-5},
	Organization = {Springer},
	Pages = {364--375},
	Publisher = {Springer International Publishing},
	Title = {Towards automatic large-scale identification of birds in audio recordings}}

@inproceedings{Fodor2013,
	Author = {G. Fodor},
	Booktitle = {2013 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)},
	Date = {2013},
	Pages = {1--2},
	Title = {The Ninth Annual MLSP Competition: First place}}

@article{Nikouei2018,
	Author = {Nikouei, Seyed Yahya and Chen, Yu and Song, Sejun and Xu, Ronghua and Choi, Baek-young and Faughnan, Timothy R},
	Date = {2018},
	Doi = {10.1109/CIC.2018.00042},
	Isbn = {9781538695029},
	Journaltitle = {2018 IEEE 4\textsuperscript{th} International Conference on Collaboration and Internet Computing (CIC)},
	Keywords = {convolutional neural network,edge computing,l-cnn,lightweight,smart surveillance},
	Pages = {256--265},
	Publisher = {IEEE},
	Title = {Smart Surveillance as an Edge Network Service : from Harr-Cascade , SVM to a Lightweight CNN},
	Bdsk-Url-1 = {https://doi.org/10.1109/CIC.2018.00042}}


@article{Murshed2019,
	Arxivid = {1908.00080},
	Author = {Murshed, M. G. Sarwar and Murphy, Christopher and Hou, Daqing and Khan, Nazar and Ananthanarayanan, Ganesh and Hussain, Faraz},
	Date = {2019},
	Eprint = {1908.00080},
	Eprinttype = {arXiv},
	Keywords = {cloud,deep learning,edge computing,edge device,fog,ing,iot,low-power,machine learn-,resource-constrained,resource-scarce,single board computer},
	Mendeley-Groups = {Deep IoT},
	Pages = {1--28},
	Title = {Machine Learning at the Network Edge: A Survey},
	Url = {http://arxiv.org/abs/1908.00080},
	Bdsk-Url-1 = {http://arxiv.org/abs/1908.00080}}

@article{Gregory2010,
	Author = {Gregory, Richard D. and van Strien, Arco and van Strien, Arco},
	Date = {2010},
	Doi = {10.2326/osj.9.3},
	Journaltitle = {Ornithological Science},
	Keywords = {biodiversity targets,birds,environmental health,population trends,there is a rich,tradition of biological monitoring,why monitoring matters,wild bird indicators},
	Number = {1},
	Pages = {3--22},
	Title = {Wild Bird Indicators: Using Composite Population Trends of Birds as Measures of Environmental Health},
	Volume = {9},
	Bdsk-Url-1 = {https://doi.org/10.2326/osj.9.3}}

@article{Stowell2019,
	Arxivid = {1807.05812},
	Author = {Stowell, Dan and Wood, Mike Michael D. and Hanna Pamuła  and Yannis Stylianou  and Hervé Glotin},
	Doi = {10.1111/2041-210X.13103},
	Eprint = {1807.05812},
	Eprinttype = {arXiv},
	Journaltitle = {Methods in Ecology and Evolution},
	Mendeley-Groups = {Bird ID},
	Number = {3},
	Pages = {368--380},
	Title = {Automatic acoustic detection of birds through deep learning: The first Bird Audio Detection challenge},
	Url = {http://arxiv.org/abs/1807.05812},
	Volume = {10},
	Bdsk-Url-1 = {http://arxiv.org/abs/1807.05812},
	Bdsk-Url-2 = {https://doi.org/10.1111/2041-210X.13103}}

@article{Zhang2018,
	Author = {Zhang, Sai Hua and Zhao, Zhao and Xu, Zhi Yong and Bellisario, Kristen and Pijanowski, Bryan C.},
	Date = {2018},
	Doi = {10.1109/ICASSP.2018.8462156},
	Isbn = {9781538646588},
	Journaltitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	Keywords = {Bird species identification,Feature selection,Spectral pattern feature,Support vector machine,Texture descriptor},
	Number = {April},
	Pages = {271--275},
	Title = {Automatic Bird Vocalization Identification Based on Fusion of Spectral Pattern and Texture Features},
	Volume = {2018-April},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICASSP.2018.8462156}}

@inproceedings{Lane2016,
	Author = {Lane, Nicholas D. and Bhattacharya, Sourav and Georgiev, Petko and Forlivesi, Claudio and Jiao, Lei and Qendro, Lorena and Kawsar, Fahim},
	Booktitle = {dl.acm.org},
	Date = {2016},
	Doi = {10.1109/IPSN.2016.7460664},
	Isbn = {9781509008025},
	Pages = {23},
	Publisher = {IEEE Press},
	Title = {DeepX: A software accelerator for low-power deep learning inference on mobile devices},
	Url = {https://dl.acm.org/citation.cfm?id=2959378},
	Bdsk-Url-1 = {https://dl.acm.org/citation.cfm?id=2959378},
	Bdsk-Url-2 = {https://doi.org/10.1109/IPSN.2016.7460664}}

@inproceedings{Chen2016,
	Author = {Chen, C and Lee, G G and Sritapan, V and Lin, C},
	Booktitle = {2016 IEEE International Workshop on Signal Processing Systems (SiPS)},
	Date = {2016},
	Doi = {10.1109/SiPS.2016.31},
	Pages = {130--135},
	Title = {Deep convolutional neural network on iOS mobile devices},
	Bdsk-Url-1 = {https://doi.org/10.1109/SiPS.2016.31}}

@article{Piczak2016,
	Author = {Piczak, Karol J.},
	Date = {2016},
	Journaltitle = {CLEF (Wlorking Notes)},
	Mendeley-Groups = {Bird ID},
	Title = {Recognizing bird species in audio recordings using deep convolutional neural networks},
	Url = {http://ceur-ws.org/Vol-1609/16090534.pdf},
	Bdsk-Url-1 = {http://ceur-ws.org/Vol-1609/16090534.pdf}}

@article{Gruenstein2017,
	Arxivid = {arXiv:1712.03603v1},
	Author = {Gruenstein, Alexander and Alvarez, Raziel and Thornton, Chris and Ghodrat, Mohammadali},
	Date = {2017},
	Eprint = {arXiv:1712.03603v1},
	Eprinttype = {arXiv},
	Number = {Nips},
	Title = {A cascade architecture for keyword spotting on mobile devices}}

@article{Sigtia2018,
	Author = {Sigtia, Siddharth and Haynes, Rob and Richards, Hywel and Marchi, Erik and Bridle, John},
	Date = {2018},
	Doi = {10.21437/Interspeech.2018-2204},
	Journaltitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	Number = {September},
	Pages = {2092--2096},
	Title = {Efficient voice trigger detection for low resource hardware},
	Volume = {2018-September},
	Bdsk-Url-1 = {https://doi.org/10.21437/Interspeech.2018-2204}}

@article{Apple2017,
	Author = {Siri~Team},
	Date = {2017},
	Journaltitle = {Apple Machine Learning Journal},
	Mendeley-Groups = {IoT},
	Number = {6},
	Title = {{Hey {S}iri: An on-device DNN-powered voice trigger for Apple's personal assistant}},
	Url = {https://machinelearning.apple.com/2017/10/01/hey-siri.html},
	Volume = {1},
	Bdsk-Url-1 = {https://machinelearning.apple.com/2017/10/01/hey-siri.html}}

@article{Zhang2018c,
	Author = {Zhang, Yingjie and Bi, Sheng and Dong, Min and Liu, Yunda},
	Date = {2018},
	Doi = {10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00074},
	Isbn = {9781538675182},
	Journaltitle = {Proceedings - IEEE 16\textsuperscript{th} International Conference on Dependable, Autonomic and Secure Computing, IEEE 16\textsuperscript{th} International Conference on Pervasive Intelligence and Computing, IEEE 4\textsuperscript{th} International Conference on Big Data Intelligence and Computing and IEEE 3},
	Keywords = {Convolutional neural network,Embedded system,NEON optimization,Object detection},
	Pages = {379--382},
	Title = {The implementation of CNN-based object detector on ARM embedded platforms},
	Volume = {50},
	Bdsk-Url-1 = {https://doi.org/10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00074}}

@article{Wei2016,
	Author = {Wei, Dai and Li, Juncheng and Pham, Phuong and Das, Samarjit and Qu, Shuhui},
	Date = {2016},
	Journaltitle = {DCASE2016 Challenge},
	Number = {September},
	Title = {Acoustic Scene Recognition with Deep Neural Networks},
	Url = {http://www.cs.tut.fi/sgn/arg/dcase2016/documents/challenge{\_}technical{\_}reports/DCASE2016{\_}Qu{\_}1017.pdf https://www.ml.cmu.edu/research/dap-papers/DAP{\_}Dai{\_}Wei.pdf},
	Bdsk-Url-1 = {http://www.cs.tut.fi/sgn/arg/dcase2016/documents/challenge%7B%5C_%7Dtechnical%7B%5C_%7Dreports/DCASE2016%7B%5C_%7DQu%7B%5C_%7D1017.pdf%20https://www.ml.cmu.edu/research/dap-papers/DAP%7B%5C_%7DDai%7B%5C_%7DWei.pdf}}

@article{You2009,
	Author = {You, Hong and Alwan, Abeer},
	Date = {2009},
	Journaltitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	Keywords = {Noise robust speech recognition,Spectro-temporal processing,Temporal modulation processing},
	Pages = {36--39},
	Title = {Temporal modulation processing of speech signals for noise robust ASR}}

@inproceedings{Chuangsuwanich2011,
	Author = {Chuangsuwanich, Ekapol and Glass, James},
	Booktitle = {Twelfth Annual Conference of the International Speech Communication Association},
	Date = {2011},
	Title = {Robust voice activity detector for real world applications using harmonicity and modulation frequency}}

@article{Chen2014,
	Author = {Chen, Guoguo and Parada, Carolina and Heigold, Georg},
	Date = {2014-05},
	Doi = {10.1109/ICASSP.2014.6854370},
	Isbn = {9781479928934},
	Journaltitle = {Acoustics, Speech and Signal {\ldots}},
	Number = {i},
	Pages = {1--5},
	Publisher = {IEEE},
	Title = {Small-footprint keyword spotting using deep neural networks},
	Url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6854370 http://ieeexplore.ieee.org/document/6854370/},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%7B%5C_%7Dall.jsp?arnumber=6854370%20http://ieeexplore.ieee.org/document/6854370/},
	Bdsk-Url-2 = {https://doi.org/10.1109/ICASSP.2014.6854370}}

@inproceedings{Boersma1993,
	Author = {Boersma, Paul},
	Booktitle = {Proceedings of the institute of phonetic sciences},
	Date = {1993},
	Number = {1193},
	Organization = {Amsterdam},
	Pages = {97--110},
	Title = {Accurate short-term analysis of the fundamental frequency and the harmonics-to-noise ratio of a sampled sound},
	Volume = {17}}

@article{Martin2001,
	Author = {Martin, Rainer},
	Date = {2001},
	Doi = {10.1109/89.928915},
	Journaltitle = {IEEE Transactions on Speech and Audio Processing},
	Keywords = {Minimum statistics,Spectral estimation,Speech enhancement},
	Number = {5},
	Pages = {504--512},
	Title = {Noise power spectral density estimation based on optimal smoothing and minimum statistics},
	Volume = {9},
	Bdsk-Url-1 = {https://doi.org/10.1109/89.928915}}

@article{Tan2010,
	Author = {Tan, Zheng-Hua and Lindberg, Borge},
	Date = {2010},
	Journaltitle = {IEEE Journal of Selected Topics in Signal Processing},
	Number = {5},
	Pages = {798--807},
	Publisher = {IEEE},
	Title = {Low-complexity variable frame rate analysis for speech recognition and voice activity detection},
	Volume = {4}}

@phdthesis{Price2016,
	Author = {Price, Michael},
	Date = {2016},
	Institution = {Massachusetts Institute of Technology},
	Keywords = {Electrical Engineering and Computer Science.,Thesis},
	Title = {Energy-scalable speech recognition circuits},
	Url = {https://dspace.mit.edu/handle/1721.1/106090},
	Bdsk-Url-1 = {https://dspace.mit.edu/handle/1721.1/106090}}

@article{Sohn1999,
	Author = {Sohn, Jongseo and Kim, Nam Soo and Sung, Wonyong},
	Date = {1999},
	Journaltitle = {IEEE signal processing letters},
	Number = {1},
	Pages = {1--3},
	Publisher = {IEEE},
	Title = {A statistical model-based voice activity detection},
	Volume = {6}}

@article{Sandler2018,
	Author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang Chieh},
	Date = {2018},
	Doi = {10.1109/CVPR.2018.00474},
	Isbn = {9781538664209},
	Journaltitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	Pages = {4510--4520},
	Publisher = {IEEE},
	Title = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
	Bdsk-Url-1 = {https://doi.org/10.1109/CVPR.2018.00474}}

@article{Mydlarz2017,
	Author = {Mydlarz, Charlie and Salamon, Justin and Bello, Juan Pablo},
	Date = {2017},
	Doi = {10.1016/j.apacoust.2016.06.010},
	Journaltitle = {Applied Acoustics},
	Keywords = {Calibration,Cyber physical system,IEC 61672,MEMS,Microphone,Noise,Smart cities},
	Number = {August 2015},
	Pages = {207--218},
	Publisher = {Elsevier Ltd},
	Title = {The implementation of low-cost urban acoustic monitoring devices},
	Volume = {117},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.apacoust.2016.06.010}}

@article{Boulmaiz2016,
	Author = {Boulmaiz, Amira and Messadeg, Djemil and Doghmane, Noureddine and Taleb-Ahmed, Abdelmalik},
	Date = {2016},
	Doi = {10.1007/s10772-016-9354-4},
	Journaltitle = {International Journal of Speech Technology},
	Keywords = {Birdsong recognition,Deep neural network,GTECC,Noise power estimation,QCN,WSN,birdsong recognition {\'a} gtecc,neural network {\'a} wsn,power estimation {\'a} deep,{\'a} qcn {\'a} noise},
	Number = {3},
	Pages = {631--645},
	Publisher = {Springer US},
	Title = {Robust acoustic bird recognition for habitat monitoring with wireless sensor networks},
	Volume = {19},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10772-016-9354-4}}

@article{Boulmaiz2017,
	Author = {Boulmaiz, Amira and Mokhtar, Badji and Messadeg, Djemil and Mokhtar, Badji and Doghmane, Noureddine and Mokhtar, Badji and Taleb-ahmed, Abdelmalik},
	Date = {2017},
	Doi = {10.4018/IJACI.2017010105},
	Keywords = {code composer studio,mel frequency cepstral coefficients,noise estimation,spectral subtraction,support,tms320c6713 dsk,tonal region detection,vector machine,waterbird recognition},
	Number = {1},
	Title = {Design and Implementation of a Robust Acoustic Recognition System for Waterbird Species using TMS320C6713 DSK},
	Volume = {8},
	Bdsk-Url-1 = {https://doi.org/10.4018/IJACI.2017010105}}

@article{Salamon2016,
	Arxivid = {1608.04363},
	Author = {Salamon, Justin and Bello, Juan Pablo},
	Date = {2016-08},
	Doi = {10.1109/LSP.2017.2657381},
	Eprint = {1608.04363},
	Eprinttype = {arXiv},
	Title = {Deep Convolutional Neural Networks and Data Augmentation for Environmental Sound Classification},
	Url = {http://arxiv.org/abs/1608.04363 http://dx.doi.org/10.1109/LSP.2017.2657381},
	Bdsk-Url-1 = {http://arxiv.org/abs/1608.04363%20http://dx.doi.org/10.1109/LSP.2017.2657381},
	Bdsk-Url-2 = {https://doi.org/10.1109/LSP.2017.2657381}}

@article{Xu2019,
	Author = {Xu, Jun Xiang and Lin, Tzu Ching and Yu, Tsai Ching and Tai, Tzu Chiang and Chang, Pao Chi},
	Date = {2019},
	Doi = {10.1109/ISM.2018.00038},
	Isbn = {9781538668573},
	Journaltitle = {Proceedings - 2018 IEEE International Symposium on Multimedia, ISM 2018},
	Pages = {267--270},
	Publisher = {IEEE},
	Title = {Acoustic scene classification using reduced mobilenet architecture},
	Bdsk-Url-1 = {https://doi.org/10.1109/ISM.2018.00038}}

@inproceedings{Incze2018,
  author={Á. {Incze} and H. {Jancsó} and Z. {Szilágyi} and A. {Farkas} and C. {Sulyok}},
	Booktitle = {SISY 2018 - IEEE 16\textsuperscript{th} International Symposium on Intelligent Systems and Informatics, Proceedings},
	Date = {2018},
	Doi = {10.1109/SISY.2018.8524677},
	Isbn = {9781538668405},
	Keywords = {audio classification,bird sound recognition,convolutional neural network,transfer learning},
	Pages = {295--300},
	Publisher = {IEEE},
	Title = {Bird Sound Recognition Using a Convolutional Neural Network},
	Url = {https://ieeexplore.ieee.org/document/8524677/},
	Bdsk-Url-1 = {https://ieeexplore.ieee.org/document/8524677/},
	Bdsk-Url-2 = {https://doi.org/10.1109/SISY.2018.8524677}}

@article{He2016,
	Author = {He, Kaiming and Sun, Jian},
	Date = {2016},
	Pages = {1--9},
	Title = {Deep Residual Learning for Image Recognition}}

@article{Krizhevsky2012,
	Arxivid = {1102.0183},
	Author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	Date = {2012},
	Doi = {10.1016/j.protcy.2014.09.007},
	Eprint = {1102.0183},
	Eprinttype = {arXiv},
	Isbn = {9781627480031},
	Journaltitle = {Proceedings of the 25\textsuperscript{th} International Conference on Neural Information Processing Systems},
	Keywords = {approximate computing,deep neural networks,hybrid bit-},
	Location = {USA},
	Number = {6},
	Pages = {1097--1105},
	Pmid = {7491034},
	Publisher = {Curran Associates Inc.},
	Series = {NIPS1́2},
	Title = {ImageNet Classification with Deep Convolutional Neural Networks},
	Url = {http://dl.acm.org/citation.cfm?doid=3098997.3065386 https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	Volume = {60},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?doid=3098997.3065386%20https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.protcy.2014.09.007}}

@article{Ma2018,
	Author = {Ma, Yufei and Cao, Yu and Vrudhula, Sarma and Seo, Jae-sun Sun},
	Date = {2018},
	Doi = {10.1109/TVLSI.2018.2815603},
	Journaltitle = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
	Keywords = {Accelerator architectures,convolutional neural networks (CNNs),field-programmable gate array (FPGA),neural network hardware},
	Number = {7},
	Pages = {1354--1367},
	Publisher = {IEEE},
	Title = {Optimizing the Convolution Operation to Accelerate Deep Neural Networks on FPGA},
	Url = {https://ieeexplore.ieee.org/document/8330049/},
	Volume = {26},
	Bdsk-Url-1 = {https://ieeexplore.ieee.org/document/8330049/},
	Bdsk-Url-2 = {https://doi.org/10.1109/TVLSI.2018.2815603}}

@article{Sarma2018,
	Author = {Sarma, Mousmita and Ghahremani, Pegah and Povey, Daniel and Goel, Nagendra Kumar and Sarma, Kandarpa Kumar and Dehak, Najim},
	Date = {2018},
	Doi = {10.21437/Interspeech.2018-1353},
	Journaltitle = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	Pages = {3097--3101},
	Title = {Emotion identification from raw speech signals using DNNs},
	Volume = {2018-September},
	Bdsk-Url-1 = {https://doi.org/10.21437/Interspeech.2018-1353}}

@article{Giammatteo2019,
	Author = {Giammatteo, Paolo and Fiordigigli, Federico Vincenzo and Pomante, Luigi and Di Mascio, Tania and Caruso, Federica},
	Date = {2019},
	Doi = {10.1109/meco.2019.8760160},
	Isbn = {9781728117409},
	Keywords = {-component,age and gender classification,deep,edge-computing,face recognition,learning},
	Number = {June},
	Pages = {1--4},
	Title = {Age \& Gender Classifier for Edge Computing},
	Bdsk-Url-1 = {https://doi.org/10.1109/meco.2019.8760160}}

@article{Simonyan2014,
	Author = {Simonyan, Karen and Zisserman, Andrew},
	Date = {2014},
	Journaltitle = {arXiv preprint arXiv:1409.1556},
	Title = {Very deep convolutional networks for large-scale image recognition}}

@inproceedings{Pellegrini2017,
	Arxivid = {1807.02776},
	Author = {Pellegrini, Thomas},
	Booktitle = {EUSIPCO},
	Date = {2017},
	Doi = {10.23919/EUSIPCO.2017.8081506},
	Eprint = {1807.02776},
	Eprinttype = {arXiv},
	Isbn = {9780992862671},
	Keywords = {Birds - Training - Convolution - Feature extractio},
	Number = {September},
	Pages = {1734--1738},
	Title = {Densely Connected CNNs for Bird Audio Detection},
	Url = {http://arxiv.org/abs/1807.02776 http://dx.doi.org/10.23919/EUSIPCO.2017.8081506 https://ieeexplore.ieee.org/abstract/document/8081506},
	Volume = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1807.02776%20http://dx.doi.org/10.23919/EUSIPCO.2017.8081506%20https://ieeexplore.ieee.org/abstract/document/8081506},
	Bdsk-Url-2 = {https://doi.org/10.23919/EUSIPCO.2017.8081506}}

@article{Hasanpour2016,
	Arxivid = {1608.06037},
	Author = {Hasanpour, Seyyed Hossein and Rouhani, Mohammad and Fayyaz, Mohsen and Sabokrou, Mohammad},
	Date = {2016},
	Eprint = {1608.06037},
	Eprinttype = {arXiv},
	Pages = {1--18},
	Title = {Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures},
	Url = {http://arxiv.org/abs/1608.06037},
	Bdsk-Url-1 = {http://arxiv.org/abs/1608.06037}}

@article{Salas2019,
	Author = {Araya-Salas, Marcelo and Smith-Vidaurre, Grace and Webster, Michael},
	Date = {2019},
	Date-Modified = {2019-12-17 19:48:13 +0800},
	Doi = {10.1080/09524622.2017.1396498},
	Journaltitle = {Bioacoustics},
	Keywords = {Sound file compression,acoustic analysis,cross-correlation,dynamic-time warping,mp3,spectrographic parameters},
	Number = {1},
	Pages = {57--73},
	Publisher = {Taylor \& Francis},
	Title = {Assessing the effect of sound file compression and background noise on measures of acoustic signal structure},
	Url = {http://doi.org/10.1080/09524622.2017.1396498 https://www.tandfonline.com/doi/full/10.1080/09524622.2017.1396498},
	Volume = {28},
	Bdsk-Url-1 = {http://doi.org/10.1080/09524622.2017.1396498%20https://www.tandfonline.com/doi/full/10.1080/09524622.2017.1396498},
	Bdsk-Url-2 = {http://doi.org/10.1080/09524622.2017.1396498}}

@article{Montero2018,
	Author = {Velasco-Montero, Delia and Fernandez-Berni, Jorge and Carmona-Galan, Ricardo and Rodriguez-Vazquez, Angel},
	Date = {2018},
	Doi = {10.1109/ACCESS.2018.2869929},
	Journaltitle = {IEEE Access},
	Keywords = {Benchmarking,convolutional neural networks,deep learning,edge inference,embedded vision,high-level specifications},
	Pages = {51680--51692},
	Title = {Optimum Selection of DNN Model and Framework for Edge Inference},
	Volume = {6},
	Bdsk-Url-1 = {https://doi.org/10.1109/ACCESS.2018.2869929}}

@article{Potamitis2014,
	Author = {Potamitis, Ilyas and Ntalampiras, Stavros and Jahn, Olaf and Riede, Klaus},
	Date = {2014},
	Doi = {10.1016/j.apacoust.2014.01.001},
	Journaltitle = {Applied Acoustics},
	Keywords = {Bird recognition, Birdsong detection, Computational ecology},
	Pages = {1--9},
	Publisher = {Elsevier Ltd},
	Title = {Automatic bird sound detection in long real-field recordings: Applications and tools},
	Volume = {80},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.apacoust.2014.01.001}}

@article{Zhang2017,
	Author = {Zhang, Yundong and Suda, Naveen and Lai, Liangzhen and Chandra, Vikas},
	Date = {2017},
	Journaltitle = {arXiv preprint arXiv:1711.07128},
	Title = {Hello Edge: Keyword spotting on microcontrollers},
	Url = {http://arxiv.org/abs/1711.07128v3},
	Bdsk-Url-1 = {http://arxiv.org/abs/1711.07128v3}}

@inproceedings{Zhang2018a,
	Author = {Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
	Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	Date = {2018},
	Pages = {6848--6856},
	Title = {ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices}}

@article{Howard2017,
	Author = {Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	Date = {2017},
	Title = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
	Url = {http://arxiv.org/abs/1704.04861},
	Bdsk-Url-1 = {http://arxiv.org/abs/1704.04861}}

@article{Zhao2017,
	Author = {Zhao, Zhao and Zhang, Sai-hua and Xu, Zhi-yong and Bellisario, Kristen and Dai, Nian-hua and Omrani, Hichem and Pijanowski, Bryan C},
	Date = {2017},
	Doi = {10.1016/j.ecoinf.2017.04.003},
	Journaltitle = {Ecological Informatics},
	Keywords = {Automated acoustic event detection, Autoregressive model, Bioacoustics monitoring, Gaussian mixture model, Robust bird species classification},
	Number = {4},
	Pages = {99--108},
	Publisher = {Elsevier},
	Title = {Automated bird acoustic event detection and robust species classification},
	Url = {http://dx.doi.org/10.1016/j.ecoinf.2017.04.003 https://www.sciencedirect.com/science/article/pii/S157495411630231X},
	Volume = {39},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.ecoinf.2017.04.003%20https://www.sciencedirect.com/science/article/pii/S157495411630231X},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.ecoinf.2017.04.003}}

@article{Hill2018,
	Author = {Hill, Andrew P and Prince, Peter and  Evelyn Piña Covarrubias and Doncaster, C Patrick and Snaddon, Jake L and Rogers, Alex},
	Date = {2018},
	Journaltitle = {Methods in Ecology and Evolution},
	Number = {5},
	Pages = {1199--1211},
	Publisher = {Wiley Online Library},
	Title = {AudioMoth: Evaluation of a smart open acoustic device for monitoring biodiversity and the environment},
	Volume = {9}}

@article{Sethi2018,
	Author = {Sethi, Sarab S and Ewers, Robert M and Jones, Nick S and Orme, Christopher David L and Picinali, Lorenzo},
	Date = {2018},
	Doi = {10.1111/2041-210X.13089},
	Editor = {Parrini, Francesca},
	Journaltitle = {Methods in Ecology and Evolution},
	Keywords = {acoustic monitoring, autonomous monitoring, biodiversity monitoring, ecosystem monitoring, open‐source software, real‐time monitoring},
	Number = {12},
	Pages = {2383--2387},
	Publisher = {John Wiley \& Sons, Ltd (10.1111)},
	Title = {Robust, real‐time and autonomous monitoring of ecosystems with an open, low‐cost, networked device},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13089 https://zenodo.org/record/1405359{\#}.XUve2XEzZGo},
	Volume = {9},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13089%20https://zenodo.org/record/1405359%7B%5C#%7D.XUve2XEzZGo},
	Bdsk-Url-2 = {https://doi.org/10.1111/2041-210X.13089}}

@article{Kasten2012,
	Author = {Kasten, Eric P and Gage, Stuart H and Fox, Jordan and Joo, Wooyeong},
	Date = {2012},
	Journaltitle = {Ecological Informatics},
	Pages = {50--67},
	Publisher = {Elsevier},
	Title = {The remote environmental assessment laboratory{\'s} acoustic library: An archive for studying soundscape ecology},
	Volume = {12}}

@article{Hu2009,
	Author = {Hu, Wen and Bulusu, Nirupama and Chou, Chun Tung and Jha, Sanjay and Taylor, Andrew and Tran, Van Nghia},
	Date = {2009},
	Journaltitle = {ACM Transactions on Sensor Networks (TOSN)},
	Number = {1},
	Pages = {4},
	Publisher = {ACM},
	Title = {Design and evaluation of a hybrid sensor network for cane toad monitoring},
	Volume = {5}}

@article{Vellinga2015,
	Author = {Vellinga, Willem Pier and Planque, Robert},
	Date = {2015},
	Keywords = {Automated recognition, Bird sounds, BirdCLEF2015, Citizen science, Data mining, LifeCLEF2015, Xeno-canto},
	Title = {The Xeno-canto collection and its relation to sound recognition and classification},
	Volume = {1391}}

@article{MacAodha2018,
	Author = {Mac Aodha, Oisin and Gibb, Rory and Barlow, Kate E and Browning, Ella and Firman, Michael and Freeman, Robin and Harder, Briana and Kinsey, Libby and Mead, Gary R and Newson, Stuart E and Pandourski, Ivan and Parsons, Stuart and Russ, Jon and Szodoray-Paradi, Abigel and Szodoray-Paradi, Farkas and Tilova, Elena and Girolami, Mark and Brostow, Gabriel and Jones, Kate E},
	Date = {2018},
	Doi = {10.1371/journal.pcbi.1005995},
	Journaltitle = {PLoS Computational Biology},
	Number = {3},
	Pages = {1--19},
	Title = {Bat detective---Deep learning tools for bat acoustic signal detection},
	Volume = {14},
	Bdsk-Url-1 = {https://doi.org/10.1371/journal.pcbi.1005995}}

@article{Oliveira2015,
	Author = {de Oliveira, Allan G and Ventura, Thiago M and Ganchev, Todor D and de Figueiredo, Josiel M and Jahn, Olaf and Marques, Marinez I and Schuchmann, Karl-L. L},
	Date = {2015},
	Doi = {10.1016/j.apacoust.2015.04.014},
	Journaltitle = {Applied Acoustics},
	Keywords = {Acoustic activity detection, Bird sound recognition, Computational bioacoustics, Feature extraction, Southern Lapwing Vanellus chilensis, acoustic activity detection, computational bioacoustics},
	Pages = {34--42},
	Publisher = {Elsevier Ltd},
	Title = {Bird acoustic activity detection based on morphological filtering of the spectrogram},
	Url = {https://www.sciencedirect.com/science/article/abs/pii/S0003682X15001309 http://dx.doi.org/10.1016/j.apacoust.2015.04.014},
	Volume = {98},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/abs/pii/S0003682X15001309%20http://dx.doi.org/10.1016/j.apacoust.2015.04.014},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.apacoust.2015.04.014}}

@article{Xie2019,
	Author = {Xie, Jie and Zhu, Mingying},
	Date = {2019},
	Doi = {10.1016/j.ecoinf.2019.05.007},
	Pages = {74--81},
	Publisher = {Elsevier},
	Title = {Handcrafted features and late fusion with deep learning for bird sound classification},
	Volume = {52},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.ecoinf.2019.05.007}}

@article{Wolfgang2016,
	Author = {Wolfgang, Andrew and Haines, Aaron},
	Date = {2016},
	Doi = {10.1656/045.023.0206},
	Journaltitle = {Northeastern Naturalist},
	Number = {2},
	Pages = {249--258},
	Title = {Testing Automated Call-Recognition Software for Winter Bird Vocalizations},
	Volume = {23},
	Bdsk-Url-1 = {https://doi.org/10.1656/045.023.0206}}

@article{Cheng2010,
	Author = {Cheng, Jinkui and Sun, Yuehua and Ji, Liqiang},
	Date = {2010},
	Number = {11},
	Pages = {3846--3852},
	Publisher = {Elsevier},
	Title = {A call-independent and automatic acoustic system for the individual recognition of animals: A novel model using four passerines},
	Volume = {43}}

@book{Marler2004,
	Author = {Marler, Peter R and Slabbekoorn, Hans},
	Date = {2004},
	Publisher = {Elsevier},
	Title = {Nature{\'s} music: the science of birdsong}}

@article{Sze2017,
	Author = {Sze, Vivienne and Chen, Yu-Hsin and Yang, Tien-Ju and Emer, Joel S},
	Date = {2017},
	Journaltitle = {Proceedings of the IEEE},
	Number = {12},
	Pages = {2295--2329},
	Publisher = {Ieee},
	Title = {Efficient processing of deep neural networks: A tutorial and survey},
	Volume = {105}}

@article{Ventura2015,
	Author = {Ventura, Thiago Meirelles and De Oliveira, Allan G and Ganchev, Todor D and De Figueiredo, Josiel M and Jahn, Olaf and Marques, Marinez I and Schuchmann, Karl L},
	Date = {2015},
	Doi = {10.1016/j.eswa.2015.07.002},
	Journaltitle = {Expert Systems with Applications},
	Keywords = {Bird identification, Computational bioacoustics, Hidden Markov Model (HMM), Mel Frequency Cepstral Coefficients (MFCCs), Robust frame selection},
	Number = {22},
	Pages = {8463--8471},
	Publisher = {Elsevier Ltd.},
	Title = {Audio parameterization with robust frame selection for improved bird identification},
	Volume = {42},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.eswa.2015.07.002}}

@article{Prince2019,
	Author = {Prince, Peter and Hill, Andrew and  Evelyn Piña Covarrubias and Doncaster, Patrick and Snaddon, Jake and Rogers, Alex},
	Date = {2019},
	Doi = {10.3390/s19030553},
	Journaltitle = {Sensors},
	Number = {3},
	Pages = {553},
	Publisher = {Multidisciplinary Digital Publishing Institute},
	Title = {Deploying Acoustic Detection Algorithms on Low-Cost, Open-Source Acoustic Sensors for Environmental Monitoring},
	Url = {http://www.mdpi.com/1424-8220/19/3/553},
	Volume = {19},
	Bdsk-Url-1 = {http://www.mdpi.com/1424-8220/19/3/553},
	Bdsk-Url-2 = {https://doi.org/10.3390/s19030553}}

@article{Aide2013,
	Author = {Aide, T Mitchell and Corrada-Bravo, Carlos and Campos-Cerqueira, Marconi and Milan, Carlos and Vega, Giovany and Alvarez, Rafael},
	Date = {2013},
	Doi = {10.7717/peerj.103},
	Journal = {PeerJ},
	Keywords = {Acoustic monitoring, Animal vocalization, Long-term monitoring, Machine learning, Species-specific algorithms},
	Publisher = {PeerJ Inc.},
	Title = {Real-time bioacoustics monitoring and automated species identification},
	Url = {https://peerj.com/articles/103},
	Volume = {1},
	Bdsk-Url-1 = {https://peerj.com/articles/103},
	Bdsk-Url-2 = {https://doi.org/10.7717/peerj.103}}

@article{Kalan2015,
	Author = {Kalan, Ammie K and Mundry, Roger and Wagner, Oliver J J and Heinicke, Stefanie and Boesch, Christophe and Kuhl, Hjalmar S},
	Date = {2015},
	Journaltitle = {Ecological Indicators},
	Pages = {217--226},
	Publisher = {Elsevier},
	Title = {Towards the automated detection and occupancy estimation of primates using passive acoustic monitoring},
	Volume = {54}}

@article{Raghuram2016,
	Author = {Raghuram, M A and Chavan, Nikhil R and Belur, Ravikiran and Koolagudi, Shashidhar G and Nikhil Chavan, Bullet R and Ravikiran Belur, Bullet and Shashidhar Koolagudi, Bullet G},
	Date = {2016},
	Doi = {10.1007/s10772-016-9372-2},
	Keywords = {Audio processing, Bird call, Bird habitat, Bird species, Bird weight, Machine learning},
	Number = {4},
	Pages = {791--804},
	Publisher = {Springer US},
	Title = {Bird classification based on their sound patterns},
	Volume = {19},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10772-016-9372-2}}

@article{Anderson1996,
	Author = {Anderson, Sven E. and Dave, Amish S. and Margoliash, Daniel},
	Date = {1996},
	Journaltitle = {The Journal of the Acoustical Society of America},
	Number = {2},
	Pages = {1209--1219},
	Title = {Template‐based automatic recognition of birdsong syllables from continuous recordings},
	Volume = {100}}

@article{Hill2012,
	Author = {Hill, Samuel D and Ji, Weihong and Parker, Kevin and Amiot, Christophe and Wells, Sarah},
	Date = {2012},
	Number = {2},
	Pages = {214--223},
	Title = {A comparison of vocalisations between mainland tui (Prosthemadera novaeseelandiae novaeseelandiae) and Chatham Island tui (P. n. chathamensis)},
	Volume = {37}}

@article{Zottesso2018,
	Author = {Zottesso, Rafael H. D. and Costa, Yandre M G and Bertolini, Diego and Oliveira, Luiz E S},
	Date = {2018},
	Doi = {10.1016/j.ecoinf.2018.08.007},
	Journaltitle = {Ecological Informatics},
	Pages = {187--197},
	Publisher = {Elsevier},
	Title = {Bird species identification using spectrogram and dissimilarity approach},
	Volume = {48},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.ecoinf.2018.08.007}}

@article{Merchant2015,
	Author = {Merchant, Nathan D and Fristrup, Kurt M and Johnson, Mark P and Tyack, Peter L and Witt, Matthew J and Blondel, Philippe and Parks, Susan E},
	Date = {2015},
	Doi = {10.1111/2041-210X.12330},
	Journaltitle = {Methods in Ecology and Evolution},
	Number = {3},
	Pages = {257--265},
	Title = {Measuring acoustic habitats},
	Volume = {6},
	Bdsk-Url-1 = {https://doi.org/10.1111/2041-210X.12330}}

@article{Laje2002,
	Author = {Laje, Rodrigo and Gardner, Timothy J and Mindlin, Gabriel B},
	Date = {2002},
	Number = {5},
	Pages = {51921},
	Publisher = {APS},
	Title = {Neuromuscular control of vocalizations in birdsong: a model},
	Volume = {65}}

@article{Ross2014,
	Author = {Ross, Jesse C and Allen, Paul E},
	Date = {2014},
	Doi = {10.1016/J.ECOINF.2013.12.002},
	Journaltitle = {Ecological Informatics},
	Pages = {34--39},
	Publisher = {Elsevier},
	Title = {Random Forest for improved analysis efficiency in passive acoustic monitoring},
	Url = {https://www.sciencedirect.com/science/article/pii/S1574954113001234},
	Volume = {21},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S1574954113001234},
	Bdsk-Url-2 = {https://doi.org/10.1016/J.ECOINF.2013.12.002}}

@inproceedings{Vilches2006,
	Author = {Vilches, Erika and Escobar, Ivan A and Vallejo, Edgar E and Taylor, Charles E},
	Booktitle = {18\textsuperscript{th} International Conference on Pattern Recognition (ICPR0́6)},
	Date = {2006},
	Organization = {IEEE},
	Pages = {400--403},
	Title = {Data mining applied to acoustic bird species recognition},
	Volume = {3}}

@article{Liu2017,
	Author = {Liu, Weibo and Wang, Zidong and Liu, Xiaohui and Zeng, Nianyin and Liu, Yurong and Alsaadi, Fuad E},
	Date = {2017},
	Journaltitle = {Neurocomputing},
	Pages = {11--26},
	Publisher = {Elsevier},
	Title = {A survey of deep neural network architectures and their applications},
	Volume = {234}}

@article{Gasc2013,
	Author = {Gasc, Amandine and Sueur, Jerome and Pavoine, Sandrine and Pellens, Roseli and Grandcolas, Philippe},
	Date = {2013},
	Journaltitle = {PLoS One},
	Number = {5},
	Publisher = {Public Library of Science},
	Title = {Biodiversity sampling using a global acoustic approach: contrasting sites with microendemics in New Caledonia},
	Volume = {8}}

@incollection{Lazarescu2016,
	Author = {Lazarescu, Mihai T},
	Booktitle = {Components and Services for IoT Platforms: Paving the Way for IoT Standards},
	Date = {2016},
	Doi = {10.1007/978-3-319-42304-3},
	Isbn = {9783319423043},
	Number = {May},
	Pages = {1--30},
	Title = {Wireless sensor networks for the internet of things: Barriers and synergies},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-3-319-42304-3}}

@article{Ovaskainen2018,
	Author = {Ovaskainen, Otso and de Camargo, Ulisses and Somervuo, Panu},
	Date = {2018},
	Doi = {10.1111/ele.13092},
	Keywords = {Automated vocal identification, autonomous audio recording, joint species distribution modelling, species classification, species identification, vocal communities},
	Number = {8},
	Pages = {1244--1254},
	Title = {Animal Sound Identifier (ASI): software for automated identification of vocal animals},
	Volume = {21},
	Bdsk-Url-1 = {https://doi.org/10.1111/ele.13092}}

@article{Ptacek2016,
	Author = {Ptacek, Ladislav and Machlica, Lukas and Linhart, Pavel and Jaska, Pavel and Muller, Ludek},
	Date = {2016},
	Number = {1},
	Pages = {55--73},
	Publisher = {Taylor \& Francis},
	Title = {Automatic recognition of bird individuals on an open set using as-is recordings},
	Volume = {25}}

@inproceedings{Salonidis2018,
	Author = {Salonidis, Theodoros and Wood, David and Ko, Bong Jun and Wang, Shiqiang and White, Graham and Conway-Jones, Dave},
	Booktitle = {Ground/Air Multisensor Interoperability, Integration, and Networking for Persistent ISR IX},
	Date = {2018},
	Doi = {10.1117/12.2306096},
	Editor = {Pham, Tien and Kolodny, Michael A and Wiegmann, Dietrich M},
	Isbn = {9781510617810},
	Keywords = {Audio analytics, Edge Computing, Machine learning},
	Pages = {24},
	Publisher = {SPIE},
	Title = {Distributed analytics for audio sensing applications},
	Volume = {10635},
	Bdsk-Url-1 = {https://doi.org/10.1117/12.2306096}}

@article{Lin2018,
	Author = {Lin, Zhong Qiu and Chung, Audrey G and Wong, Alexander},
	Date = {2018},
	Journaltitle = {arXiv preprint arXiv:1810.08559},
	Title = {Edgespeechnets: Highly efficient deep neural networks for speech recognition on the edge}}

@article{Rosales2013,
	Author = {Caycedo-Rosales, Paula Catalina and Ruiz-Munoz, Jose Francisco and Orozco-Alzate, Mauricio},
	Date = {2013},
	Date-Modified = {2019-12-17 19:47:13 +0800},
	Number = {18},
	Publisher = {EAFIT University},
	Title = {Reconocimiento automatizado de se{\~n}ales bioac{\'u}sticas: Una revisi{\'o}n de m{\'e}todos y aplicaciones},
	Volume = {9}}

@inproceedings{Adavanne2017,
	Author = {Adavanne, Sharath and Drossos, Konstantinos and Cakir, Emre and Virtanen, Tuomas},
	Booktitle = {2017 25\textsuperscript{th} European Signal Processing Conference (EUSIPCO)},
	Date = {2017-08},
	Doi = {10.23919/EUSIPCO.2017.8081505},
	Isbn = {978-0-9928626-7-1},
	Pages = {1729--1733},
	Publisher = {IEEE},
	Title = {Stacked convolutional and recurrent neural networks for bird audio detection},
	Volume = {2017},
	Bdsk-Url-1 = {https://doi.org/10.23919/EUSIPCO.2017.8081505}}

@article{Digby2013,
	Author = {Digby, Andrew and Towsey, Michael and Bell, Ben D and Teal, Paul D},
	Date = {2013},
	Doi = {10.1111/2041-210X.12060},
	Keywords = {Acoustic monitoring, Automated animal call recognition, Bioacoustics, Census, Research techniques},
	Number = {7},
	Pages = {675--683},
	Title = {A practical comparison of manual and autonomous methods for acoustic monitoring},
	Volume = {4},
	Bdsk-Url-1 = {https://doi.org/10.1111/2041-210X.12060}}

@article{Selin2007,
	Author = {Selin, Arja and Turunen, Jari and Tanttu, Juha T},
	Date = {2007},
	Doi = {10.1155/2007/51806},
	Title = {Wavelets in recognition of bird sounds},
	Volume = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1155/2007/51806}}

@article{Amjad2016,
	Author = {Amjad, Muhammad and Sharif, Muhammad and Afzal, Muhammad Khalil and Kim, Sung Won},
	Date = {2016},
	Doi = {10.1109/JSEN.2016.2519924},
	Keywords = {Wireless sensor networks, energy efficiency, operating system, sensor nodes},
	Number = {9},
	Pages = {2865--2889},
	Publisher = {IEEE},
	Title = {TinyOS-New Trends, Comparative Views, and Supported Sensing Applications: A Review},
	Volume = {16},
	Bdsk-Url-1 = {https://doi.org/10.1109/JSEN.2016.2519924}}

@book{Gaunt2004,
	Author = {Gaunt, Sandra L L and McCallum, Archibald D},
	Booktitle = {Nature's Music: The Science of Birdsong},
	Date = {2004},
	Doi = {10.1016/B978-012473070-0/50015-3},
	Isbn = {9780124730700},
	Pages = {343--362},
	Publisher = {Elsevier Inc.},
	Title = {Birdsong and conservation},
	Bdsk-Url-1 = {https://doi.org/10.1016/B978-012473070-0/50015-3}}

@article{Ganchev2012,
	Author = {Ganchev, Todor and Mporas, Iosif and Jahn, Olaf and Riede, Klaus and Schuchmann, Karl-L. L and Fakotakis, Nikos},
	Date = {2012},
	Doi = {10.1007/978-3-642-30448-4_24},
	Isbn = {9783642304477},
	Journaltitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	Keywords = {acoustic bird activity detection, bioacoustics, biodiversity surveys, real-field data},
	Pages = {190--197},
	Title = {Acoustic bird activity detection on real-field data},
	Url = {http://link.springer.com/10.1007/978-3-642-30448-4{\_}24},
	Volume = {7297 LNCS},
	Bdsk-Url-1 = {http://link.springer.com/10.1007/978-3-642-30448-4%7B%5C_%7D24},
	Bdsk-Url-2 = {https://doi.org/10.1007/978-3-642-30448-4_24}}

@inproceedings{Iandola2017,
	Author = {Iandola, Forrest and Keutzer, Kurt},
	Booktitle = {Proceedings of the Twelfth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis Companion},
	Date = {2017},
	Organization = {ACM},
	Pages = {1},
	Title = {Small neural nets are beautiful: enabling embedded systems with small deep-neural-network architectures}}

@online{Fledermausschutz2015,
	Author = {Fledermausschutz, A K},
	Date = {2015},
	Title = {Raspberry Pi Bat Projekt},
	Url = {https://www.fledermausschutz.de/wp-content/uploads/RASPBERRY{\_}PI{\_}BAT{\_}PROJEKT{\_}NEWSLETTER-EN.pdf},
	Bdsk-Url-1 = {https://www.fledermausschutz.de/wp-content/uploads/RASPBERRY%7B%5C_%7DPI%7B%5C_%7DBAT%7B%5C_%7DPROJEKT%7B%5C_%7DNEWSLETTER-EN.pdf}}

@article{Cerqueira2016,
	Author = {Campos-Cerqueira, Marconi and Aide, T Mitchell},
	Date = {2016},
	Date-Modified = {2019-12-17 19:47:07 +0800},
	Journaltitle = {Methods in Ecology and Evolution},
	Number = {11},
	Pages = {1340--1348},
	Publisher = {Wiley Online Library},
	Title = {Improving distribution data of threatened species by combining acoustic monitoring and occupancy modelling},
	Volume = {7}}

@article{Whytock2017,
	Author = {Whytock, Robin C and Christie, James},
	Date = {2017},
	Journaltitle = {Methods in Ecology and Evolution},
	Number = {3},
	Pages = {308--312},
	Publisher = {Wiley Online Library},
	Title = {Solo: an open source, customizable and inexpensive audio recorder for bioacoustic research},
	Volume = {8}}

@article{Price2018,
	Author = {Price, Michael and Glass, James and Chandrakasan, Anantha P},
	Date = {2018},
	Journaltitle = {IEEE Journal of Solid-State Circuits},
	Number = {1},
	Pages = {66--75},
	Publisher = {IEEE},
	Title = {A low-power speech recognizer and voice activity detector using deep neural networks},
	Volume = {53}}

@inproceedings{Sankupellay2018,
	Author = {Sankupellay, Mangalam and Konovalov, Dmitry},
	Booktitle = {Proceedings of ACOUSTICS},
	Date = {2018},
	Number = {9},
	Title = {Bird Call Recognition using Deep Convolutional Neural Network, ResNet-50},
	Volume = {7}}

@article{Pavan2015,
	Author = {Pavan, Gianni and Favaretto, Andrea and Bovelacci, Bruna and Scaravelli, Dino and Macchio, Stefano and Glotin, Herv{\`e}},
	Date = {2015},
	Number = {2},
	Pages = {68--74},
	Title = {Bioacoustics and Ecoacoustics Applied To Environmental Monitoring and Management},
	Volume = {39}}

@article{Todt2004,
	Author = {Todt, Dietmar},
	Date = {2004},
	Doi = {10.1029/1999GL900195},
	Keywords = {language acquisition, signal repertoires, song learning, speech segmentation, units of interaction},
	Number = {2},
	Pages = {201--208},
	Title = {From birdsong to speech: a plea for comparative approaches},
	Url = {http://www.scielo.br/pdf/aabc/v76n2/a03v76n2.pdf},
	Volume = {76},
	Bdsk-Url-1 = {http://www.scielo.br/pdf/aabc/v76n2/a03v76n2.pdf},
	Bdsk-Url-2 = {https://doi.org/10.1029/1999GL900195}}

@article{Gilbert1994,
	Author = {Gilbert, Gillian and McGregor, Peter K and Tyler, Glen},
	Date = {1994},
	Pages = {335--348},
	Publisher = {JSTOR},
	Title = {Vocal Individuality as a Census Tool: Practical Considerations Illustrated by a Study of Two Rare Species (Individualidad Vocal Como Herramienta en los Censos: Consideraciones Pr{\'a}cticas Ilustradas por un Estudio de dos Especies Raras}}

@article{Darras2019,
	Author = {Darras, Kevin and Bat{\'a}ry, P{\'e}ter and Furnas, Brett J and Grass, Ingo and Mulyani, Yeni A and Tscharntke, Teja},
	Date = {2019},
	Journaltitle = {Ecological Applications},
	Publisher = {Wiley Online Library},
	Title = {Autonomous sound recording outperforms human observation for sampling birds: a systematic map and user guide}}

@article{Cakir2017,
	Author = {Cakır, Emre and Parascandolo, Giambattista and Heittola, Toni and Huttunen, Heikki and Virtanen, Tuomas},
	Date = {2017},
	Journaltitle = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	Number = {6},
	Pages = {1291--1303},
	Publisher = {IEEE},
	Title = {Convolutional recurrent neural networks for polyphonic sound event detection},
	Volume = {25}}

@inproceedings{Knapp2016,
	Author = {Knapp, Joshua and Qu, Guangzhi and Zhang, Feng},
	Booktitle = {IEEE International Conference on Machine Learning and Applications (ICMLA)},
	Date = {2016},
	Doi = {10.1109/ICMLA.2016.0037},
	Isbn = {978-1-5090-6167-9},
	Pages = {176--181},
	Publisher = {IEEE},
	Title = {Automatic Species Recognition Based on Improved Birdsong Analysis},
	Url = {http://ieeexplore.ieee.org/document/7838141/},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/document/7838141/},
	Bdsk-Url-2 = {https://doi.org/10.1109/ICMLA.2016.0037}}


@article{Weerasena2019,
	Author = {Weerasena, Hansika and Jayawardhana, Manesh and Egodage, Dineth and Fernando, Heshan and Sooriyaarachchi, Sulochana and Gamage, Chandana and Kottege, Navinda},
	Date = {2019},
	Doi = {10.1109/TENCON.2018.8650196},
	Isbn = {9781538654576},
	Keywords = {Bioacoustic Monitoring, Bird Species Identification, Machine Learning, Signal Processing},
	Number = {October},
	Pages = {235--239},
	Publisher = {IEEE},
	Title = {Continuous Automatic Bioacoustics Monitoring of Bird Calls with Local Processing on Node Level},
	Volume = {2018-Octob},
	Bdsk-Url-1 = {https://doi.org/10.1109/TENCON.2018.8650196}}

@article{Stowell2019a,
	Arxivid = {1807.05812},
	Author = {Stowell, Dan and Stylianou, Yannis and Wood, Mike Michael D and Pamula, Hanna and Glotin, Herve and Stylianou, Yannis},
	Date = {2019},
	Doi = {10.1111/2041-210X.13103},
	Eprint = {1807.05812},
	Eprinttype = {arXiv},
	Keywords = {bird, deep learning, machine learning, passive acoustic monitoring, sound},
	Number = {3},
	Pages = {368--380},
	Title = {Automatic acoustic detection of birds through deep learning: The first Bird Audio Detection challenge},
	Url = {http://arxiv.org/abs/1807.05812},
	Volume = {10},
	Bdsk-Url-1 = {http://arxiv.org/abs/1807.05812},
	Bdsk-Url-2 = {https://doi.org/10.1111/2041-210X.13103}}

@article{Trifa2008,
	Author = {Trifa, Vlad M and Kirschel, Alexander N G and Taylor, Charles E and Vallejo, Edgar E},
	Date = {2008},
	Doi = {10.1121/1.2839017},
	Journaltitle = {The Journal of the Acoustical Society of America},
	Number = {4},
	Pages = {2424--2431},
	Title = {Automated species recognition of antbirds in a Mexican rainforest using hidden Markov models},
	Url = {https://asa.scitation.org/doi/abs/10.1121/1.2839017 http://asa.scitation.org/doi/10.1121/1.2839017},
	Volume = {123},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.2839017%20http://asa.scitation.org/doi/10.1121/1.2839017},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.2839017}}

@article{Warden2018,
	Author = {Warden, Pete},
	Date = {2018},
	Journaltitle = {arXiv preprint arXiv:1804.03209},
	Title = {Speech commands: A dataset for limited-vocabulary speech recognition}}

@book{Farina2013,
	Author = {Farina, Almo},
	Date = {2013},
	Publisher = {Springer},
	Title = {Soundscape ecology: principles, patterns, methods and applications}}

@article{Beason2019,
	Author = {Beason, Richard D and Riesch, Rudiger and Koricheva, Julia},
	Date = {2019},
	Doi = {10.1080/09524622.2018.1463293},
	Journaltitle = {Bioacoustics},
	Number = {4},
	Pages = {381--396},
	Publisher = {Taylor \& Francis},
	Title = {AURITA: an affordable, autonomous recording device for acoustic monitoring of audible and ultrasonic frequencies},
	Volume = {28},
	Bdsk-Url-1 = {https://doi.org/10.1080/09524622.2018.1463293}}

@article{Hervas2017,
	Author = {Hervas, Marcos and Alsina-Pages, Rosa Ma and Alas, Francesc and Salvador, Mart and Hervas, Marcos and Alsina-Pages, Rosa Ma and Alas, Francesc and Salvador, Mart},
	Date = {2017},
	Doi = {10.3390/s17061331},
	Number = {6},
	Pages = {1331},
	Publisher = {Multidisciplinary Digital Publishing Institute},
	Title = {An FPGA-Based WASN for Remote Real-Time Monitoring of Endangered Species: A Case Study on the Birdsong Recognition of Botaurus stellaris},
	Url = {http://www.mdpi.com/1424-8220/17/6/1331},
	Volume = {17},
	Bdsk-Url-1 = {http://www.mdpi.com/1424-8220/17/6/1331},
	Bdsk-Url-2 = {https://doi.org/10.3390/s17061331}}

@article{Maina2016,
	Author = {wa Maina, Ciira and Muchiri, David and Njoroge, Peter},
	Date = {2016},
	Journaltitle = {bioRxiv},
	Pages = {72546},
	Publisher = {Cold Spring Harbor Laboratory},
	Title = {Cost effective acoustic monitoring of biodiversity and bird populations in Kenya}}

@article{Dent2016,
	Author = {Dent, Jennifer M and Molles, Laura E},
	Date = {2016},
	Number = {4},
	Pages = {315--322},
	Publisher = {Taylor \& Francis},
	Title = {Call-based identification as a potential tool for monitoring Great Spotted Kiwi},
	Volume = {116}}

@article{Iandola2016,
	Author = {Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},
	Date = {2016},
	Journaltitle = {arXiv preprint arXiv:1602.07360},
	Title = {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size}}
